gpu_num: [0]
random_seed: 0

#model
model:
  lr: 0.00001
  batch_size: 2
  epochs: 1
  bert_model: allenai/longformer-base-4096
  optimizer: adamw
  gradient_clip: 1
  gradient_accumulation: 16


# data and model path
data:
  training_set: data/train.jsonl
  dev_set: data/dev.jsonl
  test_set: data/test.jsonl

cache_folder: /cs/labs/tomhope/forer11/cache

full_doc: true
model_path: /cs/labs/tomhope/forer11/SciCo_Retrivel/MistralInstrucv2Results/checkpoints
log: /cs/labs/tomhope/forer11/SciCo_Retrivel/logs

# definition extraction
definition_extraction: False
should_save_definition: False

should_use_new_definition: True

from_gpt: True


# inference
checkpoint_multiclass: /cs/labs/tomhope/forer11/SciCo_Retrivel/MistralInstrucv2Results/checkpoints/with_def/version_2/checkpoints/epoch=0-step=11850.ckpt
checkpoint_coref: path-to-binary-coref-ckpt
checkpoint_hypernym: path-hierarchy-model-ckpt
agg_threshold: 0.6  # for agglomerative clustering
hypernym_threshold: 0.4 # for hypernym scores
save_path: /cs/labs/tomhope/forer11/SciCo_Retrivel/MistralInstrucv2Results/checkpoints/with_def
