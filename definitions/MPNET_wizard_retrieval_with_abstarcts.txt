Processing term: unsupervised automatic facial point detection from normal terms


Unsupervised automatic facial point detection refers to the process of identifying and locating specific
points on a person's face without the need for manual labeling or prior knowledge of where these points should
be located. It involves using computer vision algorithms to analyze images of faces and identify patterns that
correspond to certain facial features, such as eyes, nose, and mouth.


From:
1. Facial emotion expressions in human-robot interaction: A survey
Abstract: Facial expressions are an ideal means of communicating one's emotions or
intentions to others. This overview will focus on human facial expression
recognition as well as robotic facial expression generation. In the case of
human facial expression recognition, both facial expression recognition on
predefined datasets as well as in real-time will be covered. For robotic facial
expression generation, hand-coded and automated methods i.e., facial
expressions of a robot are generated by moving the features (eyes, mouth) of
the robot by hand-coding or automatically using machine learning techniques,
will also be covered. There are already plenty of studies that achieve high
accuracy for emotion expression recognition on predefined datasets, but the
accuracy for facial expression recognition in real-time is comparatively lower.
In the case of expression generation in robots, while most of the robots are
capable of making basic facial expressions, there are not many studies that

2. CoNFies: Controllable Neural Face Avatars
Abstract: use automated facial action recognition (AFAR) to characterize facial
expressions as a combination of action units (AU) and their intensities. AUs
provide both the semantic locations and control labels for the system. CoNFies
outperformed competing methods for novel view and expression synthesis in terms
of visual and anatomic fidelity of expressions.

3. Facial Keypoints Detection
Abstract: Detect facial keypoints is a critical element in face recognition. However,
there is difficulty to catch keypoints on the face due to complex influences
from original images, and there is no guidance to suitable algorithms. In this
paper, we study different algorithms that can be applied to locate keyponits.
Specifically: our framework (1)prepare the data for further investigation
(2)Using PCA and LBP to process the data (3) Apply different algorithms to
analysis data, including linear regression models, tree based model, neural
network and convolutional neural network, etc. Finally we will give our
conclusion and further research topic. A comprehensive set of experiments on
dataset demonstrates the effectiveness of our framework.



Processing term: ASR from normal terms


ASR stands for Automatic Speech Recognition. It is a technology that allows computers to recognize and
understand human speech. It involves converting spoken words into text or commands that can be used by
machines.


From:
1. Extension spectrale d'un signal de parole de la bande t\'el\'ephonique
  \`a la bande AM
Abstract: speech coding.
  -----
  Le pr\'esent m\'emoire propose un syst\`eme d'extension de la bande
permettant de produire un signal en bande AM \`a partir d'un signal de parole
en bande t\'el\'ephonique. L'extension est effectu\'ee de fa\c{c}on
ind\'ependante pour les hautes fr\'equences et les basses fr\'equences.
L'extension des hautes fr\'equences utilise le mod\`ele filtre-excitation.
L'extension de l'excitation est r\'ealis\'ee dans le domaine temporel par une
fonction non lin\'eaire, alors que l'extension de l'enveloppe spectrale
s'effectue dans le domaine cepstral par un perceptron multi-couches.
L'extension de la bande basse utilise le mod\`ele sinuso\"idal. L'amplitude des
sinuso\"ides est aussi estim\'ee par un perceptron multi-couches.
  Les r\'esultats obtenus montrent que la qualit\'e sonore apr\`es extension
est sup\'erieure \`a celle de la bande t\'el\'ephonique, avec une importante
diff\'erence entre les auditeurs. Certaines techniques d\'evelopp\'ees, dont

2. Investigating data partitioning strategies for crosslinguistic
  low-resource ASR evaluation
Abstract: intensity are comparatively more predictive factors of variability regardless
of the data split. These results suggest that the widely used hold-speakers-out
approach to ASR data partitioning can yield results that do not reflect model
performance on unseen data or speakers. Random splits can yield more reliable
and generalizable estimates when facing data sparsity.

3. Data Augmentation with Locally-time Reversed Speech for Automatic Speech
  Recognition
Abstract: training sets are created by combining natural speech with different partitions
of LTR speech. The efficacy of data augmentation is confirmed by ASR results on
speech corpora in various languages and speaking styles. ASR on LTR speech with
reversed segment duration of 15 ms - 30 ms is found to have lower error rate
than with other segment duration. Data augmentation with these LTR speech
achieves satisfactory and consistent improvement on ASR performance.



Processing term: Feature Pyramid Network from normal terms


 A Feature Pyramid Network (FPN) is a type of neural network architecture used for image classification and
object detection tasks. It consists of multiple levels of feature extraction, where each level represents a
different scale of the input image. At each level, the network applies a set of convolutional filters to
generate feature maps, which are then upsampled using transposed convolutions to match the input image size.
By combining the features from all scales, the FPN can achieve higher accuracy than traditional architectures
that only use a single scale of feature extraction.


From:
1. SFPN: Synthetic FPN for Object Detection
Abstract: FPN (Feature Pyramid Network) has become a basic component of most SoTA one
stage object detectors. Many previous studies have repeatedly proved that FPN
can caputre better multi-scale feature maps to more precisely describe objects
if they are with different sizes. However, for most backbones such VGG, ResNet,
or DenseNet, the feature maps at each layer are downsized to their quarters due
to the pooling operation or convolutions with stride 2. The gap of
down-scaling-by-2 is large and makes its FPN not fuse the features smoothly.
This paper proposes a new SFPN (Synthetic Fusion Pyramid Network) arichtecture
which creates various synthetic layers between layers of the original FPN to
enhance the accuracy of light-weight CNN backones to extract objects' visual
features more accurately. Finally, experiments prove the SFPN architecture
outperforms either the large backbone VGG16, ResNet50 or light-weight backbones
such as MobilenetV2 based on AP score.

2. PINs: Progressive Implicit Networks for Multi-Scale Neural
  Representations
Abstract: leveraged separately for its respective resolution, meaning a smaller network
for coarser reconstructions. Experiments on several 2D and 3D datasets show
improvements in reconstruction accuracy, representational capacity and training
speed compared to baselines.

3. DSIC: Dynamic Sample-Individualized Connector for Multi-Scale Object
  Detection
Abstract: Although object detection has reached a milestone thanks to the great success
of deep learning, the scale variation is still the key challenge. Integrating
multi-level features is presented to alleviate the problems, like the classic
Feature Pyramid Network (FPN) and its improvements. However, the specifically
designed feature integration modules of these methods may not have the optimal
architecture for feature fusion. Moreover, these models have fixed
architectures and data flow paths, when fed with various samples. They cannot
adjust and be compatible with each kind of data. To overcome the above
limitations, we propose a Dynamic Sample-Individualized Connector (DSIC) for
multi-scale object detection. It dynamically adjusts network connections to fit
different samples. In particular, DSIC consists of two components: Intra-scale
Selection Gate (ISG) and Cross-scale Selection Gate (CSG). ISG adaptively
extracts multi-level features from backbone as the input of feature



Processing term: spatial attention mechanisms from normal terms


Spatial attention mechanisms refer to a technique used in computer vision and natural language processing to
focus on specific regions of an image or sequence of images. It involves using a neural network to assign
different weights to different parts of an image based on their relevance to the task at hand. In the case of
object tracking, spatial attention mechanisms can be used to identify and prioritize the location of the
target object within the scene. By focusing on the relevant areas of the image, the algorithm can improve its
accuracy and reduce the likelihood of false positives.


From:
1. Towards Robust Visual Tracking for Unmanned Aerial Vehicle with
  Tri-Attentional Correlation Filters
Abstract: Object tracking has been broadly applied in unmanned aerial vehicle (UAV)
tasks in recent years. However, existing algorithms still face difficulties
such as partial occlusion, clutter background, and other challenging visual
factors. Inspired by the cutting-edge attention mechanisms, a novel object
tracking framework is proposed to leverage multi-level visual attention. Three
primary attention, i.e., contextual attention, dimensional attention, and
spatiotemporal attention, are integrated into the training and detection stages
of correlation filter-based tracking pipeline. Therefore, the proposed tracker
is equipped with robust discriminative power against challenging factors while
maintaining high operational efficiency in UAV scenarios. Quantitative and
qualitative experiments on two well-known benchmarks with 173 challenging UAV
video sequences demonstrate the effectiveness of the proposed framework. The

2. MixFormer: End-to-End Tracking with Iterative Mixed Attention
Abstract: Tracking often uses a multi-stage pipeline of feature extraction, target
information integration, and bounding box estimation. To simplify this pipeline
and unify the process of feature extraction and target information integration,
we present a compact tracking framework, termed as MixFormer, built upon
transformers. Our core design is to utilize the flexibility of attention
operations, and propose a Mixed Attention Module (MAM) for simultaneous feature
extraction and target information integration. This synchronous modeling scheme
allows to extract target-specific discriminative features and perform extensive
communication between target and search area. Based on MAM, we build our
MixFormer tracking framework simply by stacking multiple MAMs with progressive
patch embedding and placing a localization head on top. In addition, to handle
multiple target templates during online tracking, we devise an asymmetric

3. SRRT: Search Region Regulation Tracking
Abstract: Dominant trackers generate a fixed-size rectangular region based on the
previous prediction or initial bounding box as the model input, i.e., search
region. While this manner leads to improved tracking efficiency, a fixed-size
search region lacks flexibility and is likely to fail in cases, e.g., fast
motion and distractor interference. Trackers tend to lose the target object due
to the limited search region or be interfered by distractors due to excessive
search region. In this work, we propose a novel tracking paradigm, called
Search Region Regulation Tracking (SRRT), which applies a proposed search
region regulator to estimate an optimal search region dynamically for every
frame. To adapt the object's appearance variation during tracking, we further
propose a locking-state determined updating strategy for reference frame
updating. Our SRRT framework is very concise without fancy design, yet achieves
evident improvements on the baselines and competitive results with other



Processing term: JPEG method from normal terms


The term "JPEG method" is not defined in the given context. However, based on the context provided, it seems
that the term refers to a specific technique used for compressing images using the Joint Photographic Experts
Group (JPEG) algorithm.


From:
1. Image Splicing Detection, Localization and Attribution via JPEG Primary
  Quantization Matrix Estimation and Clustering
Abstract: including aligned and non-aligned double JPEG compression, and regardless of
whether the second compression is stronger or weaker than the first one. We
validated the proposed approach by means of extensive experiments showing its
superior performance with respect to baseline methods working in similar
conditions.

2. Image compression overview
Abstract: from the original image. We want to cover compression techniques mainly from
the last decade. Many of them are variations of existing ones, only some of
them uses new principes.

3. Image compression overview
Abstract: Compression plays a significant role in a data storage and a transmission. If
we speak about a generall data compression, it has to be a lossless one. It
means, we are able to recover the original data 1:1 from the compressed file.
Multimedia data (images, video, sound...), are a special case. In this area, we
can use something called a lossy compression. Our main goal is not to recover
data 1:1, but only keep them visually similar. This article is about an image
compression, so we will be interested only in image compression. For a human
eye, it is not a huge difference, if we recover RGB color with values
[150,140,138] instead of original [151,140,137]. The magnitude of a difference
determines the loss rate of the compression. The bigger difference usually
means a smaller file, but also worse image quality and noticable differences
from the original image. We want to cover compression techniques mainly from
the last decade. Many of them are variations of existing ones, only some of



Processing term: video data generation from normal terms


Video data generation refers to the process of creating or collecting digital video data. It can be done
manually or automatically through various techniques such as capturing footage from cameras, downloading
online videos, or generating synthetic videos using computer graphics. The generated videos may have different
purposes such as entertainment, education, advertising, or scientific research.


From:
1. Clarification of Video Retrieval Query Results by the Automated
  Insertion of Supporting Shots
Abstract: Computational Video Editing Systems output video generally follows a
particular form, e.g. conversation or music videos, in this way they are domain
specific. We describe a recent development in our video annotation and
segmentation system to support general computational video editing in which we
derive a single generic editing strategy from general cinema narrative
principles instead of using a hierarchical film gram-mar. We demonstrate how
this single principle coupled with a database of scripts derived from annotated
videos leverages the existing video editing knowledge encoded within the
editing of those sequences in a flexible and generic manner. We discuss the
cinema theory foundations for this generic editing strategy, review the
algorithms used to effect it, and goon by means of examples to show its
appropriateness in an automated system.

2. CREATE: A Benchmark for Chinese Short Video Retrieval and Title
  Generation
Abstract: ALignment WIth Generation with the help of video tags and a GPT pre-trained
model. CREATE opens new directions for facilitating future research and
applications on video titling and video retrieval in the field of Chinese short
videos.

3. MSVD-Turkish: A Comprehensive Multimodal Dataset for Integrated Vision
  and Language Research in Turkish
Abstract: Automatic generation of video descriptions in natural language, also called
video captioning, aims to understand the visual content of the video and
produce a natural language sentence depicting the objects and actions in the
scene. This challenging integrated vision and language problem, however, has
been predominantly addressed for English. The lack of data and the linguistic
properties of other languages limit the success of existing approaches for such
languages. In this paper we target Turkish, a morphologically rich and
agglutinative language that has very different properties compared to English.
To do so, we create the first large scale video captioning dataset for this
language by carefully translating the English descriptions of the videos in the
MSVD (Microsoft Research Video Description Corpus) dataset into Turkish. In
addition to enabling research in video captioning in Turkish, the parallel
English-Turkish descriptions also enables the study of the role of video



Processing term: weight update from hard 20 terms


 A weight update is a process in which the weights of a neural network are adjusted during the training
process to improve its performance on a particular task. This is done by calculating the gradient of the loss
function with respect to the weights and then applying an optimization algorithm to update them.


From:
1. Investigating the locality of neural network training dynamics
Abstract: In the recent past a certain property of neural training trajectories in
weight-space had been isolated, that of "local elasticity" ($\srel$) - which
attempts to quantify the propagation of influence of a sampled data point on
the prediction at another data point. In this work, we embark on a
comprehensive study of local elasticity. Firstly, specific to the
classification setting, we suggest a new definition of the original idea of
$\srel$. Via experiments on state-of-the-art neural networks training on SVHN,
CIFAR-10 and CIFAR-100 we demonstrate how our new $\srel$ detects the property
of the weight updates preferring to make changes in predictions within the same
class as of the sampled data. Next, we demonstrate via examples of neural
regression that the original $\srel$ reveals a $2-$phase behavior: that their
training proceeds via an initial elastic phase when $\srel$ changes rapidly and
an eventual inelastic phase when $\srel$ remains large. Lastly, we give

2. The activity-weight duality in feed forward neural networks: The
  geometric determinants of generalization
Abstract: One of the fundamental problems in machine learning is generalization. In
neural network models with a large number of weights (parameters), many
solutions can be found to fit the training data equally well. The key question
is which solution can describe testing data not in the training set. Here, we
report the discovery of an exact duality (equivalence) between changes in
activities in a given layer of neurons and changes in weights that connect to
the next layer of neurons in a densely connected layer in any feed forward
neural network. The activity-weight (A-W) duality allows us to map variations
in inputs (data) to variations of the corresponding dual weights. By using this
mapping, we show that the generalization loss can be decomposed into a sum of
contributions from different eigen-directions of the Hessian matrix of the loss
function at the solution in weight space. The contribution from a given
eigen-direction is the product of two geometric factors (determinants): the

3. Fixed Points of Cone Mapping with the Application to Neural Networks
Abstract: physical assumptions, because even assuming that the input and output are to be
non-negative, the weights can have (small, but) less than zero values. Such
properties (often found in papers on the interpretability of weights of neural
networks) lead to the weakening of the assumptions about the monotonicity or
scalability of the mapping associated with the neural network. To the best of
our knowledge, this paper is the first to study this phenomenon.



Processing term: Understanding Behaviors of Neurons from hard 20 terms


Understanding Behaviors of Neurons refers to the ability to understand how neurons in the brain respond to
different stimuli and how they interact with each other to produce cognitive processes such as memory,
perception, and decision-making. It involves studying the electrical and chemical signals that neurons
transmit and receiving, as well as the structures and functions of the neurons themselves.


From:
1. A brain basis of dynamical intelligence for AI and computational
  neuroscience
Abstract: expressed through neural synchrony, nested oscillations, and flexible
sequences, provide a rich computational layer for reading and updating
hierarchical models distributed in long-term memory networks. Moreover,
embracing agent-centered paradigms in AI and CN will accelerate our
understanding of the complex dynamics and behaviors that build useful world
models. A convergence of AI/CN theories and objectives will reveal dynamical
principles of intelligence for brains and engineered learning systems. This
article was inspired by our symposium on dynamical neuroscience and machine
learning at the 6th Annual US/NIH BRAIN Initiative Investigators Meeting.

2. Modelling Neuronal Behaviour with Time Series Regression: Recurrent
  Neural Networks on C. Elegans Data
Abstract: Given the inner complexity of the human nervous system, insight into the
dynamics of brain activity can be gained from understanding smaller and simpler
organisms, such as the nematode C. Elegans. The behavioural and structural
biology of these organisms is well-known, making them prime candidates for
benchmarking modelling and simulation techniques. In these complex neuronal
collections, classical, white-box modelling techniques based on intrinsic
structural or behavioural information are either unable to capture the profound
nonlinearities of the neuronal response to different stimuli or generate
extremely complex models, which are computationally intractable. In this paper
we show how the nervous system of C. Elegans can be modelled and simulated with
data-driven models using different neural network architectures. Specifically,
we target the use of state of the art recurrent neural networks architectures
such as LSTMs and GRUs and compare these architectures in terms of their

3. Excitable Networks for Finite State Computation with Continuous Time
  Recurrent Neural Networks
Abstract: Continuous time recurrent neural networks (CTRNN) are systems of coupled
ordinary differential equations that are simple enough to be insightful for
describing learning and computation, from both biological and machine learning
viewpoints. We describe a direct constructive method of realising finite state
input-dependent computations on an arbitrary directed graph. The constructed
system has an excitable network attractor whose dynamics we illustrate with a
number of examples. The resulting CTRNN has intermittent dynamics: trajectories
spend long periods of time close to steady-state, with rapid transitions
between states. Depending on parameters, transitions between states can either
be excitable (inputs or noise needs to exceed a threshold to induce the
transition), or spontaneous (transitions occur without input or noise). In the
excitable case, we show the threshold for excitability can be made arbitrarily
sensitive.



Processing term: policy gradient methods from hard 20 terms


Policy gradient methods refer to a family of reinforcement learning algorithms that aim to optimize a policy
by iteratively updating the policy parameters based on the gradient of some performance metric with respect to
the policy. In the context of Q-learning, policy gradient methods can be used to improve the convergence speed
of Q-learning by taking advantage of the fact that the Q-value function is typically smoother than the action-
value function. However, policy gradient methods often suffer from high variance in the gradient estimates,
which can lead to slow convergence or instability. Variance reduction techniques such as actor-critic methods
can be used to address this issue by combining value and advantage functions to train both the policy and the
value function more efficiently.


From:
1. On Policy Gradients
Abstract: The goal of policy gradient approaches is to find a policy in a given class
of policies which maximizes the expected return. Given a differentiable model
of the policy, we want to apply a gradient-ascent technique to reach a local
optimum. We mainly use gradient ascent, because it is theoretically well
researched. The main issue is that the policy gradient with respect to the
expected return is not available, thus we need to estimate it. As policy
gradient algorithms also tend to require on-policy data for the gradient
estimate, their biggest weakness is sample efficiency. For this reason, most
research is focused on finding algorithms with improved sample efficiency. This
paper provides a formal introduction to policy gradient that shows the
development of policy gradient approaches, and should enable the reader to
follow current research on the topic.

2. Policy Gradient and Actor-Critic Learning in Continuous Time and Space:
  Theory and Algorithms
Abstract: We study policy gradient (PG) for reinforcement learning in continuous time
and space under the regularized exploratory formulation developed by Wang et
al. (2020). We represent the gradient of the value function with respect to a
given parameterized stochastic policy as the expected integration of an
auxiliary running reward function that can be evaluated using samples and the
current value function. This effectively turns PG into a policy evaluation (PE)
problem, enabling us to apply the martingale approach recently developed by Jia
and Zhou (2021) for PE to solve our PG problem. Based on this analysis, we
propose two types of the actor-critic algorithms for RL, where we learn and
update value functions and policies simultaneously and alternatingly. The first
type is based directly on the aforementioned representation which involves
future trajectories and hence is offline. The second type, designed for online

3. q-Learning in Continuous Time
Abstract: We study the continuous-time counterpart of Q-learning for reinforcement
learning (RL) under the entropy-regularized, exploratory diffusion process
formulation introduced by Wang et al. (2020) As the conventional (big)
Q-function collapses in continuous time, we consider its first-order
approximation and coin the term "(little) q-function". This function is related
to the instantaneous advantage rate function as well as the Hamiltonian. We
develop a "q-learning" theory around the q-function that is independent of time
discretization. Given a stochastic policy, we jointly characterize the
associated q-function and value function by martingale conditions of certain
stochastic processes. We then apply the theory to devise different actor-critic
algorithms for solving underlying RL problems, depending on whether or not the
density function of the Gibbs measure generated from the q-function can be
computed explicitly. One of our algorithms interprets the well-known Q-learning



Processing term: satellite navigation module from hard 20 terms


 A satellite navigation module is a component or subsystem of a satellite that is responsible for providing
navigation and timing information to other devices on Earth. It typically uses Global Navigation Satellite
System (GNSS) signals, such as those provided by the US Department of Defense's Global Positioning System
(GPS), Russia's GLONASS, China's BeiDou, or Europe's Galileo, to determine its position and velocity, and then
provides this information to other devices via a communication link.


From:
1. Performance Bounds for Cooperative Localisation in the Starlink Network
Abstract: constellation's geometry and the characteristics of the inter-satellite links,
both of which could inform the use of relative navigation in large satellite
constellations in future.

2. Topology Design for GNSSs Considering Both Inter-satellite Links and
  Ground-satellite Links
Abstract: Inter-satellite links (ISLs) are adopted in global navigation satellite
systems (GNSSs) for high-precision orbit determination and space-based
end-to-end telemetry telecommand control and communications. Due to limited
onboard ISL terminals, the polling time division duplex (PTDD) mechanism is
usually proposed for space link layer networking. By extending the polling
mechanism to ground-satellite links (GSLs), a unified management system of the
space segment and the ground segment can be realized. However, under the
polling system how to jointly design the topology of ISLs and GSLs during every
slot to improve data interaction has not been studied. In this paper, we
formulate the topology design problem as an integer linear programming, aiming
at minimizing the average delay of data delivery from satellites to ground
stations while satisfying the ranging requirement for the orbit determination.
To tackle the computational complexity problem, we first present a novel

3. Heterogeneous Federated CubeSat System: problems, constraints and
  capabilities
Abstract: Different arguments were being presented in the last decade about CubeSats
and their applications. Some of them address wireless communication (5G and 6G
technologies) trying to achieve better characteristics as coverage and
connectivity. Some arrived with terms as IoST (Internet of Space Things),
Internet of Satellites (IoSat), DSS (Distributed Space Systems), and FSS
(Federated Satellite Systems). All of them aim to use Small/NanoSatellites as
constellations/swarms is to provide specific services, share unused resources,
and evolve the concept of satellites-as-a-service (SaS). This paper aims to
emophasize performance attributes of such cyber-physical systems, model their
inherent operational constraints and at the very end, evaluate the quality of
service in terms of figures of merit for the entering/leaving of new
heterogeneous constituent systems, a.k.a satellites, to the constellation. This
"whitepaper"-styled work focuses on presenting the definitions of this

/cs/labs/tomhope/forer11/vnev_2/lib/python3.9/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(


Processing term: GRU from hard 20 terms


GRU stands for Gated Recurrent Unit. It is a type of recurrent neural network (RNN) cell that is commonly used
in the context of natural language processing (NLP). The GRU cell is designed to handle sequential data, such
as text or speech, by maintaining a memory of previous inputs while still allowing for flexibility in the
output. The "gated" aspect of the GRU refers to the fact that there is a gate mechanism that controls the flow
of information into and out of the memory cell. The GRU cell has been found to be particularly effective in
tasks such as machine translation, where the input sequence needs to be predicted based on previously seen
inputs.


From:
1. Reward Optimization for Neural Machine Translation with Learned Metrics
Abstract: Neural machine translation (NMT) models are conventionally trained with
token-level negative log-likelihood (NLL), which does not guarantee that the
generated translations will be optimized for a selected sequence-level
evaluation metric. Multiple approaches are proposed to train NMT with BLEU as
the reward, in order to directly improve the metric. However, it was reported
that the gain in BLEU does not translate to real quality improvement, limiting
the application in industry. Recently, it became clear to the community that
BLEU has a low correlation with human judgment when dealing with
state-of-the-art models. This leads to the emerging of model-based evaluation
metrics. These new metrics are shown to have a much higher human correlation.
In this paper, we investigate whether it is beneficial to optimize NMT models
with the state-of-the-art model-based metric, BLEURT. We propose a
contrastive-margin loss for fast and stable reward optimization suitable for

2. English-Japanese Neural Machine Translation with
  Encoder-Decoder-Reconstructor
Abstract: Neural machine translation (NMT) has recently become popular in the field of
machine translation. However, NMT suffers from the problem of repeating or
missing words in the translation. To address this problem, Tu et al. (2017)
proposed an encoder-decoder-reconstructor framework for NMT using
back-translation. In this method, they selected the best forward translation
model in the same manner as Bahdanau et al. (2015), and then trained a
bi-directional translation model as fine-tuning. Their experiments show that it
offers significant improvement in BLEU scores in Chinese-English translation
task. We confirm that our re-implementation also shows the same tendency and
alleviates the problem of repeating and missing words in the translation on a
English-Japanese task too. In addition, we evaluate the effectiveness of
pre-training by comparing it with a jointly-trained model of forward
translation and back-translation.

3. Gating Dropout: Communication-efficient Regularization for Sparsely
  Activated Transformers
Abstract: local machines, thus reducing the cross-machine communication. Similar to
traditional dropout, we also show that Gating Dropout has a regularization
effect during training, resulting in improved generalization performance. We
validate the effectiveness of Gating Dropout on multilingual machine
translation tasks. Our results demonstrate that Gating Dropout improves a
state-of-the-art MoE model with faster wall-clock time convergence rates and
better BLEU scores for a variety of model sizes and datasets.



Processing term: ReLU from hard 20 terms


ReLU stands for Rectified Linear Unit, which is a type of activation function commonly used in neural
networks. It is defined as f(x) = max(0,x), which means that it returns 0 for any input below 0 and the input
itself for any input greater than or equal to 0.


From:
1. Neural Network Approximation of Refinable Functions
Abstract: In the desire to quantify the success of neural networks in deep learning and
other applications, there is a great interest in understanding which functions
are efficiently approximated by the outputs of neural networks. By now, there
exists a variety of results which show that a wide range of functions can be
approximated with sometimes surprising accuracy by these outputs. For example,
it is known that the set of functions that can be approximated with exponential
accuracy (in terms of the number of parameters used) includes, on one hand,
very smooth functions such as polynomials and analytic functions (see e.g.
\cite{E,S,Y}) and, on the other hand, very rough functions such as the
Weierstrass function (see e.g. \cite{EPGB,DDFHP}), which is nowhere
differentiable. In this paper, we add to the latter class of rough functions by
showing that it also includes refinable functions. Namely, we show that
refinable functions are approximated by the outputs of deep ReLU networks with

2. Static analysis of ReLU neural networks with tropical polyhedra
Abstract: polyhedra. We show that tropical polyhedra can efficiently abstract ReLU
activation function, while being able to control the loss of precision due to
linear computations. We show how the connection between ReLU networks and
tropical rational functions can provide approaches for range analysis of ReLU
neural networks.

3. Neural Network Approximation of Refinable Functions
Abstract: showing that it also includes refinable functions. Namely, we show that
refinable functions are approximated by the outputs of deep ReLU networks with
a fixed width and increasing depth with accuracy exponential in terms of their
number of parameters. Our results apply to functions used in the standard
construction of wavelets as well as to functions constructed via subdivision
algorithms in Computer Aided Geometric Design.



Processing term: L2 from hard 20 terms


L2 refers to the second power of the magnitude of a vector or matrix. It is commonly used in control theory to
measure the distance between two signals or states. In the context of linear, parameter-varying (LPV) systems,
the L2 norm of a signal is used to estimate the performance of the system.


From:
1. Computation of lower bounds for the induced L2 norm of LPV systems
Abstract: proposed lower bound algorithm has two benefits. First, the lower bound
complements standard upper bound techniques. Specifically, a small gap between
the bounds indicates that further computation, e.g. upper bounds with more
complex Lyapunov functions, is unnecessary. Second, the lower bound algorithm
returns a bad parameter trajectory for the LPV system that can be further
analyzed to provide insight into the system performance.

2. Computation of lower bounds for the induced L2 norm of LPV systems
Abstract: Determining the induced L2 norm of a linear, parameter-varying (LPV) system
is an integral part of many analysis and robust control design procedures. Most
prior work has focused on efficiently computing upper bounds for the induced L2
norm. The conditions for upper bounds are typically based on scaled small-gain
theorems with dynamic multipliers or dissipation inequalities with parameter
dependent Lyapunov functions. This paper presents a complementary algorithm to
compute lower bounds for the induced L2 norm. The proposed approach computes a
lower bound on the gain by restricting the parameter trajectory to be a
periodic signal. This restriction enables the use of recent results for exact
calculation of the L2 norm for a periodic linear time varying system. The
proposed lower bound algorithm has two benefits. First, the lower bound
complements standard upper bound techniques. Specifically, a small gap between

3. Event-Triggered l2-Optimal Formation Control with State-Estimation for
  Agents Modeled as LPV Systems
Abstract: condition is violated. The design procedure guarantees stability and bounded
l2-performance. Furthermore, the estimators are interchangeable for a given
controller. We compare in simulation zero-order hold, open-loop estimation, and
closed-loop estimation strategies. Simulation trials are carried out with
non-holonomic dynamic unicycles modeled as polytopic LPV systems.



Processing term: robust speech or speaker recognition from hard 20 terms


Robust speech or speaker recognition refers to speech technology that can accurately recognize speech even in
challenging conditions such as background noise, accents, and variations in speaking rate. It involves using
advanced algorithms and machine learning techniques to extract relevant features from speech signals and then
using these features to distinguish between different speakers or types of speech events.


From:
1. Unsupervised Voice Activity Detection by Modeling Source and System
  Information using Zero Frequency Filtering
Abstract: Voice activity detection (VAD) is an important pre-processing step for speech
technology applications. The task consists of deriving segment boundaries of
audio signals which contain voicing information. In recent years, it has been
shown that voice source and vocal tract system information can be extracted
using zero-frequency filtering (ZFF) without making any explicit model
assumptions about the speech signal. This paper investigates the potential of
zero-frequency filtering for jointly modeling voice source and vocal tract
system information, and proposes two approaches for VAD. The first approach
demarcates voiced regions using a composite signal composed of different
zero-frequency filtered signals. The second approach feeds the composite signal
as input to the rVAD algorithm. These approaches are compared with other
supervised and unsupervised VAD methods in the literature, and are evaluated on
the Aurora-2 database, across a range of SNRs (20 to -5 dB). Our studies show

2. Improvement of Noise-Robust Single-Channel Voice Activity Detection with
  Spatial Pre-processing
Abstract: Voice activity detection (VAD) remains a challenge in noisy environments.
With access to multiple microphones, prior studies have attempted to improve
the noise robustness of VAD by creating multi-channel VAD (MVAD) methods.
However, MVAD is relatively new compared to single-channel VAD (SVAD), which
has been thoroughly developed in the past. It might therefore be advantageous
to improve SVAD methods with pre-processing to obtain superior VAD, which is
under-explored. This paper improves SVAD through two pre-processing methods, a
beamformer and a spatial target speaker detector. The spatial detector sets
signal frames to zero when no potential speaker is present within a target
direction. The detector may be implemented as a filter, meaning the input
signal for the SVAD is filtered according to the detector's output; or it may
be implemented as a spatial VAD to be combined with the SVAD output. The
evaluation is made on a noisy reverberant speech database, with clean speech

3. SG-VAD: Stochastic Gates Based Speech Activity Detection
Abstract: We propose a novel voice activity detection (VAD) model in a low-resource
environment. Our key idea is to model VAD as a denoising task, and construct a
network that is designed to identify nuisance features for a speech
classification task. We train the model to simultaneously identify irrelevant
features while predicting the type of speech event. Our model contains only
7.8K parameters, outperforms the previously proposed methods on the AVA-Speech
evaluation set, and provides comparative results on the HAVIC dataset. We
present its architecture, experimental results, and ablation study on the
model's components. We publish the code and the models here
https://www.github.com/jsvir/vad.



Processing term: end-to-end deep neural network from hard 10 terms


An end-to-end deep neural network refers to a type of artificial intelligence algorithm that combines multiple
layers of artificial neurons into a single network, allowing it to learn and perform complex tasks without
needing to be trained separately for each individual task. In the context of autonomous driving, end-to-end
deep neural networks are used for perception, prediction, and planning tasks related to navigation and
control.


From:
1. Autonomous Vehicle Control: End-to-end Learning in Simulated Urban
  Environments
Abstract: In recent years, considerable progress has been made towards a vehicle's
ability to operate autonomously. An end-to-end approach attempts to achieve
autonomous driving using a single, comprehensive software component. Recent
breakthroughs in deep learning have significantly increased end-to-end systems'
capabilities, and such systems are now considered a possible alternative to the
current state-of-the-art solutions. This paper examines end-to-end learning for
autonomous vehicles in simulated urban environments containing other vehicles,
traffic lights, and speed limits. Furthermore, the paper explores end-to-end
systems' ability to execute navigational commands and examines whether improved
performance can be achieved by utilizing temporal dependencies between
subsequent visual cues. Two end-to-end architectures are proposed: a
traditional Convolutional Neural Network and an extended design combining a
Convolutional Neural Network with a recurrent layer. The models are trained

2. Container: Context Aggregation Network
Abstract: Convolutional neural networks (CNNs) are ubiquitous in computer vision, with
a myriad of effective and efficient variations. Recently, Transformers --
originally introduced in natural language processing -- have been increasingly
adopted in computer vision. While early adopters continue to employ CNN
backbones, the latest networks are end-to-end CNN-free Transformer solutions. A
recent surprising finding shows that a simple MLP based solution without any
traditional convolutional or Transformer components can produce effective
visual representations. While CNNs, Transformers and MLP-Mixers may be
considered as completely disparate architectures, we provide a unified view
showing that they are in fact special cases of a more general method to
aggregate spatial context in a neural network stack. We present the \model
(CONText AggregatIon NEtwoRk), a general-purpose building block for multi-head
context aggregation that can exploit long-range interactions \emph{a la}

3. Scalable Primitives for Generalized Sensor Fusion in Autonomous Vehicles
Abstract: In autonomous driving, there has been an explosion in the use of deep neural
networks for perception, prediction and planning tasks. As autonomous vehicles
(AVs) move closer to production, multi-modal sensor inputs and heterogeneous
vehicle fleets with different sets of sensor platforms are becoming
increasingly common in the industry. However, neural network architectures
typically target specific sensor platforms and are not robust to changes in
input, making the problem of scaling and model deployment particularly
difficult. Furthermore, most players still treat the problem of optimizing
software and hardware as entirely independent problems. We propose a new end to
end architecture, Generalized Sensor Fusion (GSF), which is designed in such a
way that both sensor inputs and target tasks are modular and modifiable. This
enables AV system designers to easily experiment with different sensor
configurations and methods and opens up the ability to deploy on heterogeneous



Processing term: Conv ( ) filter from hard 10 terms


 A "Conv" or "Convolution" filter is a type of layer in a neural network used for feature extraction. It
applies a set of filters to the input data to identify patterns and extract features. The output of a Conv
filter is a matrix of feature maps that represent the extracted features. The size of the filter depends on
the desired level of abstraction and the size of the input data. In the given context, it means that before
applying the DU-Net, a Conv filter with a stride of 2 and a max pooling layer was applied to reduce the number
of features from 128 to 64.


From:
1. NTIRE 2022 Challenge on Efficient Super-Resolution: Methods and Results
Abstract: This paper reviews the NTIRE 2022 challenge on efficient single image
super-resolution with focus on the proposed solutions and results. The task of
the challenge was to super-resolve an input image with a magnification factor
of $\times$4 based on pairs of low and corresponding high resolution images.
The aim was to design a network for single image super-resolution that achieved
improvement of efficiency measured according to several metrics including
runtime, parameters, FLOPs, activations, and memory consumption while at least
maintaining the PSNR of 29.00dB on DIV2K validation set. IMDN is set as the
baseline for efficiency measurement. The challenge had 3 tracks including the
main track (runtime), sub-track one (model complexity), and sub-track two
(overall performance). In the main track, the practical runtime performance of
the submissions was evaluated. The rank of the teams were determined directly
by the absolute value of the average runtime on the validation set and test

2. IMDeception: Grouped Information Distilling Super-Resolution Network
Abstract: Single-Image-Super-Resolution (SISR) is a classical computer vision problem
that has benefited from the recent advancements in deep learning methods,
especially the advancements of convolutional neural networks (CNN). Although
state-of-the-art methods improve the performance of SISR on several datasets,
direct application of these networks for practical use is still an issue due to
heavy computational load. For this purpose, recently, researchers have focused
on more efficient and high-performing network structures. Information
multi-distilling network (IMDN) is one of the highly efficient SISR networks
with high performance and low computational load. IMDN achieves this efficiency
with various mechanisms such as Intermediate Information Collection (IIC),
working in a global setting, Progressive Refinement Module (PRM), and Contrast
Aware Channel Attention (CCA), employed in a local setting. These mechanisms,

3. Neural Architecture Search for Image Super-Resolution Using Densely
  Constructed Search Space: DeCoNAS
Abstract: define a complexity-based penalty for solving image super-resolution, which can
be considered a multi-objective problem. Experiments show that our DeCoNASNet
outperforms the state-of-the-art lightweight super-resolution networks designed
by handcraft methods and existing NAS-based design.



Processing term: Time Series Analysis from hard 10 terms


Time series analysis is the process of analyzing data over time to identify patterns, trends, and seasonal
variations. It involves using statistical techniques to model and forecast future values based on past
observations. There are various types of time series analysis techniques, including regression analysis,
forecasting, and hypothesis testing. Bootstrap is a resampling method used in time series analysis to estimate
confidence intervals and test hypotheses about the mean of a time series. The choice of resampling method
depends on the nature of the data and the research question being addressed.


From:
1. Skip-sampling: subsampling in the frequency domain
Abstract: Over the last 35 years, several bootstrap methods for time series have been
proposed. Popular `time-domain' methods include the block-bootstrap, the
stationary bootstrap, the linear process bootstrap, etc.; subsampling for time
series is also available, and is closely related to the block-bootstrap.
`Frequency-domain' bootstrap has been performed either by resampling the
periodogram ordinates or by resampling the ordinates of the Discrete Fourier
Transform (DFT). The paper at hand proposes a novel construction of subsampling
the DFT ordinates, and investigates its theoretical properties and realm of
applicability.

2. Sampling rate-corrected analysis of irregularly sampled time series
Abstract: The analysis of irregularly sampled time series remains a challenging task
requiring methods that account for continuous and abrupt changes of sampling
resolution without introducing additional biases. The edit-distance is an
effective metric to quantitatively compare time series segments of unequal
length by computing the cost of transforming one segment into the other. We
show that transformation costs generally exhibit a non-trivial relationship
with local sampling rate. If the sampling resolution undergoes strong
variations, this effect impedes unbiased comparison between different time
episodes. We study the impact of this effect on recurrence quantification
analysis, a framework that is well-suited for identifying regime shifts in
nonlinear time series. A constrained randomization approach is put forward to
correct for the biased recurrence quantification measures. This strategy
involves the generation of a novel type of time series and time axis surrogates

3. A Frequency Domain Bootstrap for General Multivariate Stationary
  Processes
Abstract: For many relevant statistics of multivariate time series, no valid frequency
domain bootstrap procedures exist. This is mainly due to the fact that the
distribution of such statistics depends on the fourth-order moment structure of
the underlying process in nearly every scenario, except for some special cases
like Gaussian time series. In contrast to the univariate case, even additional
structural assumptions such as linearity of the multivariate process or a
standardization of the statistic of interest do not solve the problem. This
paper focuses on integrated periodogram statistics as well as functions thereof
and presents a new frequency domain bootstrap procedure for multivariate time
series, the multivariate frequency domain hybrid bootstrap (MFHB), to fill this
gap. Asymptotic validity of the MFHB procedure is established for general
classes of periodogram-based statistics and for stationary multivariate



Processing term: LSTM from hard 10 terms


LSTM stands for Long Short-Term Memory, which is a type of Recurrent Neural Network (RNN) commonly used in
Natural Language Processing (NLP). It can be used for various tasks such as language modeling, sentiment
analysis, and machine translation. In the context of search engines, LSTM could potentially be used to improve
the ranking of search results by taking into account the user's previous interactions with the search results
and adjusting the ranking accordingly.


From:
1. RLIRank: Learning to Rank with Reinforcement Learning for Dynamic Search
Abstract: To support complex search tasks, where the initial information requirements
are complex or may change during the search, a search engine must adapt the
information delivery as the user's information requirements evolve. To support
this dynamic ranking paradigm effectively, search result ranking must
incorporate both the user feedback received, and the information displayed so
far. To address this problem, we introduce a novel reinforcement learning-based
approach, RLIrank. We first build an adapted reinforcement learning framework
to integrate the key components of the dynamic search. Then, we implement a new
Learning to Rank (LTR) model for each iteration of the dynamic search, using a
recurrent Long Short Term Memory neural network (LSTM), which estimates the
gain for each next result, learning from each previously ranked document. To
incorporate the user's feedback, we develop a word-embedding variation of the

2. Pre-trained Language Model based Ranking in Baidu Search
Abstract: As the heart of a search engine, the ranking system plays a crucial role in
satisfying users' information demands. More recently, neural rankers fine-tuned
from pre-trained language models (PLMs) establish state-of-the-art ranking
effectiveness. However, it is nontrivial to directly apply these PLM-based
rankers to the large-scale web search system due to the following challenging
issues:(1) the prohibitively expensive computations of massive neural PLMs,
especially for long texts in the web-document, prohibit their deployments in an
online ranking system that demands extremely low latency;(2) the discrepancy
between existing ranking-agnostic pre-training objectives and the ad-hoc
retrieval scenarios that demand comprehensive relevance modeling is another
main barrier for improving the online ranking system;(3) a real-world search
engine typically involves a committee of ranking components, and thus the
compatibility of the individually fine-tuned ranking model is critical for a

3. UNIMIB at TREC 2021 Clinical Trials Track
Abstract: This contribution summarizes the participation of the UNIMIB team to the TREC
2021 Clinical Trials Track. We have investigated the effect of different query
representations combined with several retrieval models on the retrieval
performance. First, we have implemented a neural re-ranking approach to study
the effectiveness of dense text representations. Additionally, we have
investigated the effectiveness of a novel decision-theoretic model for
relevance estimation. Finally, both of the above relevance models have been
compared with standard retrieval approaches. In particular, we combined a
keyword extraction method with a standard retrieval process based on the BM25
model and a decision-theoretic relevance model that exploits the
characteristics of this particular search task. The obtained results show that
the proposed keyword extraction method improves 84% of the queries over the
TREC's median NDCG@10 measure when combined with either traditional or



Processing term: MLP from hard 10 terms


 MLP stands for Multilayer Perceptron, which is a type of neural network architecture commonly used in
supervised learning tasks.


From:
1. Teaching a Machine to Diagnose a Heart Disease; Beginning from
  digitizing scanned ECGs to detecting the Brugada Syndrome (BrS)
Abstract: extracted data and that makes the diagnosis. The proposed pipeline
distinguishes between three major types of ECG images and recreates each
recorded lead signal. Features and quality are retained during the digitization
of the data, albeit some encountered issues are not fully removed (Part I).
Nevertheless, the results of the aforesaid program are suitable for further
investigation of the ECG by a computational method such as the proposed
classifier which proves the concept and could be the architectural basis for
future research (Part II). This thesis is divided into two parts as they are
part of the same process but conceptually different. It is hoped that this work
builds a new foundation for computational investigations in the case of the BrS
and its diagnosis.

2. Identifying the Mislabeled Training Samples of ECG Signals using Machine
  Learning
Abstract: The classification accuracy of electrocardiogram signal is often affected by
diverse factors in which mislabeled training samples issue is one of the most
influential problems. In order to mitigate this negative effect, the method of
cross validation is introduced to identify the mislabeled samples. The method
utilizes the cooperative advantages of different classifiers to act as a filter
for the training samples. The filter removes the mislabeled training samples
and retains the correctly labeled ones with the help of 10-fold cross
validation. Consequently, a new training set is provided to the final
classifiers to acquire higher classification accuracies. Finally, we
numerically show the effectiveness of the proposed method with the MIT-BIH
arrhythmia database.

3. Investigating myocardial infarction and its effects in patients with
  urgent medical problems using advanced data mining tools
Abstract: 105 medical records of myocardial infarction patients with fourteen features
including age, the time of emergency operation, Creatine Phosphokinase (CPK)
test, heart rate, blood sugar, and vein are gathered and investigated through
classification techniques of data analysis including random decision forests,
decision tree, support vector machine (SVM), k-nearest neighbor, and ordinal
logistic regression. Finally, the model of random decision forests with an
accuracy of 76% is selected as the best model in terms of the mean evaluation
indicator. Also, seven features of the creatine Phosphokinase test, urea, white
and red blood cell count, blood sugar, time, and hemoglobin are identified as
the most effective features of the ejection fraction variable.



Processing term: categorical data analysis technique from hard 10 terms


Categorical data analysis techniques refer to statistical methods used to analyze and interpret categorical
data. Categorical data is data that can be grouped into categories or classes, such as gender, race,
occupation, or education level. Categorical data analysis techniques include chi-square tests, contingency
tables, logistic regression, and decision trees.


From:
1. Modified Bivariate Weibull Distribution Allowing Instantaneous and Early
  Failures
Abstract: and test the performance of the proposed methodologies. The method is also
applied to real data and compared with existing approaches to model such data
in the literature.

2. Unobserved classes and extra variables in high-dimensional discriminant
  analysis
Abstract: suitable for data of large dimensions. A simulation study and an artificial
experiment related to classification of adulterated honey samples are used to
validate the ability of the proposed framework to deal with complex situations.

3. Improved Customer Transaction Classification using Semi-Supervised
  Knowledge Distillation
Abstract: distillation frameworks. The approach identifies the category of a transaction
using free text input given by the customer. We use weak labelling and notice
that the performance gains are similar to that of using human-annotated
samples. On a large internal dataset and on 20Newsgroup dataset, we see that
RoBERTa performs the best for the categorization tasks. Further, using an
ALBERT model (it has 33x fewer parameters vis-a-vis parameters of RoBERTa),
with RoBERTa as the Teacher, we see a performance similar to that of RoBERTa
and better performance over unadapted ALBERT. This framework, with ALBERT as a
student and RoBERTa as teacher, is further referred to as R-ALBERT in this
paper. The model is in production and is used by business to understand
changing trends and take appropriate decisions.